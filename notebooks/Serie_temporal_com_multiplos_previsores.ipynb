{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMX2tU6EzSfVz9s2jTfNnPN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anderson1292/Artificial_intelligence/blob/main/notebooks/Serie_temporal_com_multiplos_previsores.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heFWFYlqJxXy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Dense,Dropout,LSTM\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import ReduceLROnPlateau,ModelCheckpoint,EarlyStopping\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base = pd.read_csv('petr4_treinamento.csv')\n",
        "base.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "vkU0tjQoKWl3",
        "outputId": "585f9e3c-dbcd-4ee6-8f10-cc7901e28e46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Date       Open       High        Low      Close  Adj Close  \\\n",
              "0  2013-01-02  19.990000  20.209999  19.690001  19.690001  18.086271   \n",
              "1  2013-01-03  19.809999  20.400000  19.700001  20.400000  18.738441   \n",
              "2  2013-01-04  20.330000  20.620001  20.170000  20.430000  18.766001   \n",
              "3  2013-01-07  20.480000  20.670000  19.950001  20.080000  18.444506   \n",
              "4  2013-01-08  20.110001  20.230000  19.459999  19.500000  17.911745   \n",
              "\n",
              "       Volume  \n",
              "0  30182600.0  \n",
              "1  30552600.0  \n",
              "2  36141000.0  \n",
              "3  28069600.0  \n",
              "4  29091300.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a39d0ab6-3f30-48c1-b0af-9d0d649700b3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2013-01-02</td>\n",
              "      <td>19.990000</td>\n",
              "      <td>20.209999</td>\n",
              "      <td>19.690001</td>\n",
              "      <td>19.690001</td>\n",
              "      <td>18.086271</td>\n",
              "      <td>30182600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2013-01-03</td>\n",
              "      <td>19.809999</td>\n",
              "      <td>20.400000</td>\n",
              "      <td>19.700001</td>\n",
              "      <td>20.400000</td>\n",
              "      <td>18.738441</td>\n",
              "      <td>30552600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2013-01-04</td>\n",
              "      <td>20.330000</td>\n",
              "      <td>20.620001</td>\n",
              "      <td>20.170000</td>\n",
              "      <td>20.430000</td>\n",
              "      <td>18.766001</td>\n",
              "      <td>36141000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2013-01-07</td>\n",
              "      <td>20.480000</td>\n",
              "      <td>20.670000</td>\n",
              "      <td>19.950001</td>\n",
              "      <td>20.080000</td>\n",
              "      <td>18.444506</td>\n",
              "      <td>28069600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2013-01-08</td>\n",
              "      <td>20.110001</td>\n",
              "      <td>20.230000</td>\n",
              "      <td>19.459999</td>\n",
              "      <td>19.500000</td>\n",
              "      <td>17.911745</td>\n",
              "      <td>29091300.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a39d0ab6-3f30-48c1-b0af-9d0d649700b3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a39d0ab6-3f30-48c1-b0af-9d0d649700b3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a39d0ab6-3f30-48c1-b0af-9d0d649700b3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base = base.dropna()"
      ],
      "metadata": {
        "id": "lRD63zVFKngR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_train = base.iloc[:,1:7].values"
      ],
      "metadata": {
        "id": "YqKBsMzAKrIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalization of values\n",
        "normalized = MinMaxScaler(feature_range=(0,1))\n",
        "base_train_norm = normalized.fit_transform(base_train)"
      ],
      "metadata": {
        "id": "ivjerCjjLDbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_predictors = MinMaxScaler(feature_range=(0,1))\n",
        "normalized_predictors.fit_transform(base_train[:,0:1])"
      ],
      "metadata": {
        "id": "kQC0pkwgS-UY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictors = []\n",
        "real_price = []\n",
        "\n",
        "for i in range(90,1242):\n",
        "  predictors.append(base_train_norm[i-90:i,0:6])\n",
        "  real_price.append(base_train_norm[i,0])\n",
        "predictors,real_price = np.array(predictors),np.array(real_price)"
      ],
      "metadata": {
        "id": "BpjGjnBdLh7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(100,return_sequences=True,input_shape=(predictors.shape[1],6)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(LSTM(50,return_sequences=True))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(LSTM(50,return_sequences=True))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(LSTM(50))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.compile(optimizer='rmsprop',loss='mean_squared_error',metrics=['mean_absolute_error'])"
      ],
      "metadata": {
        "id": "OhSAOJRDMU21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.fit(predictors,real_price,epochs=100,batch_size=32)\n",
        "early = EarlyStopping(monitor='loss',min_delta=1e-10,patience=10,verbose=1)\n",
        "reduce = ReduceLROnPlateau(monitor='loss',factor=0.2,patience=5,verbose=1)\n",
        "model_check = ModelCheckpoint(filepath='weights.h5',monitor='loss',save_best_only=True,verbose=1)"
      ],
      "metadata": {
        "id": "ooTUO4SLOH-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(predictors,real_price,epochs=100,batch_size=32,\n",
        "          callbacks=[early,reduce,model_check])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zc0xQwusUedP",
        "outputId": "4a189a4d-1445-4065-e801-18e29f21bf46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "34/36 [===========================>..] - ETA: 0s - loss: 0.0189 - mean_absolute_error: 0.1078\n",
            "Epoch 1: loss improved from inf to 0.01810, saving model to weights.h5\n",
            "36/36 [==============================] - 10s 21ms/step - loss: 0.0181 - mean_absolute_error: 0.1047 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "34/36 [===========================>..] - ETA: 0s - loss: 0.0072 - mean_absolute_error: 0.0670\n",
            "Epoch 2: loss improved from 0.01810 to 0.00773, saving model to weights.h5\n",
            "36/36 [==============================] - 1s 20ms/step - loss: 0.0077 - mean_absolute_error: 0.0693 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "34/36 [===========================>..] - ETA: 0s - loss: 0.0059 - mean_absolute_error: 0.0597\n",
            "Epoch 3: loss improved from 0.00773 to 0.00580, saving model to weights.h5\n",
            "36/36 [==============================] - 1s 19ms/step - loss: 0.0058 - mean_absolute_error: 0.0593 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "34/36 [===========================>..] - ETA: 0s - loss: 0.0044 - mean_absolute_error: 0.0521\n",
            "Epoch 4: loss improved from 0.00580 to 0.00464, saving model to weights.h5\n",
            "36/36 [==============================] - 1s 20ms/step - loss: 0.0046 - mean_absolute_error: 0.0533 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0043 - mean_absolute_error: 0.0514\n",
            "Epoch 5: loss improved from 0.00464 to 0.00428, saving model to weights.h5\n",
            "36/36 [==============================] - 1s 19ms/step - loss: 0.0043 - mean_absolute_error: 0.0514 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "35/36 [============================>.] - ETA: 0s - loss: 0.0040 - mean_absolute_error: 0.0492\n",
            "Epoch 6: loss improved from 0.00428 to 0.00416, saving model to weights.h5\n",
            "36/36 [==============================] - 1s 18ms/step - loss: 0.0042 - mean_absolute_error: 0.0495 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "34/36 [===========================>..] - ETA: 0s - loss: 0.0036 - mean_absolute_error: 0.0455\n",
            "Epoch 7: loss improved from 0.00416 to 0.00388, saving model to weights.h5\n",
            "36/36 [==============================] - 1s 19ms/step - loss: 0.0039 - mean_absolute_error: 0.0471 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "34/36 [===========================>..] - ETA: 0s - loss: 0.0030 - mean_absolute_error: 0.0428\n",
            "Epoch 8: loss improved from 0.00388 to 0.00304, saving model to weights.h5\n",
            "36/36 [==============================] - 1s 19ms/step - loss: 0.0030 - mean_absolute_error: 0.0432 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "35/36 [============================>.] - ETA: 0s - loss: 0.0034 - mean_absolute_error: 0.0445\n",
            "Epoch 9: loss did not improve from 0.00304\n",
            "36/36 [==============================] - 1s 18ms/step - loss: 0.0035 - mean_absolute_error: 0.0451 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "34/36 [===========================>..] - ETA: 0s - loss: 0.0030 - mean_absolute_error: 0.0426\n",
            "Epoch 10: loss improved from 0.00304 to 0.00296, saving model to weights.h5\n",
            "36/36 [==============================] - 1s 19ms/step - loss: 0.0030 - mean_absolute_error: 0.0421 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "35/36 [============================>.] - ETA: 0s - loss: 0.0025 - mean_absolute_error: 0.0381\n",
            "Epoch 11: loss improved from 0.00296 to 0.00249, saving model to weights.h5\n",
            "36/36 [==============================] - 1s 19ms/step - loss: 0.0025 - mean_absolute_error: 0.0381 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "34/36 [===========================>..] - ETA: 0s - loss: 0.0027 - mean_absolute_error: 0.0397\n",
            "Epoch 12: loss did not improve from 0.00249\n",
            "36/36 [==============================] - 1s 18ms/step - loss: 0.0026 - mean_absolute_error: 0.0396 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "34/36 [===========================>..] - ETA: 0s - loss: 0.0026 - mean_absolute_error: 0.0383\n",
            "Epoch 13: loss did not improve from 0.00249\n",
            "36/36 [==============================] - 1s 20ms/step - loss: 0.0025 - mean_absolute_error: 0.0380 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "34/36 [===========================>..] - ETA: 0s - loss: 0.0024 - mean_absolute_error: 0.0382\n",
            "Epoch 14: loss improved from 0.00249 to 0.00241, saving model to weights.h5\n",
            "36/36 [==============================] - 1s 20ms/step - loss: 0.0024 - mean_absolute_error: 0.0380 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "34/36 [===========================>..] - ETA: 0s - loss: 0.0023 - mean_absolute_error: 0.0369\n",
            "Epoch 15: loss improved from 0.00241 to 0.00225, saving model to weights.h5\n",
            "36/36 [==============================] - 1s 19ms/step - loss: 0.0023 - mean_absolute_error: 0.0363 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "35/36 [============================>.] - ETA: 0s - loss: 0.0022 - mean_absolute_error: 0.0356\n",
            "Epoch 16: loss improved from 0.00225 to 0.00215, saving model to weights.h5\n",
            "36/36 [==============================] - 1s 19ms/step - loss: 0.0021 - mean_absolute_error: 0.0355 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "34/36 [===========================>..] - ETA: 0s - loss: 0.0022 - mean_absolute_error: 0.0365\n",
            "Epoch 17: loss improved from 0.00215 to 0.00213, saving model to weights.h5\n",
            "36/36 [==============================] - 1s 19ms/step - loss: 0.0021 - mean_absolute_error: 0.0360 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "34/36 [===========================>..] - ETA: 0s - loss: 0.0020 - mean_absolute_error: 0.0338\n",
            "Epoch 18: loss improved from 0.00213 to 0.00196, saving model to weights.h5\n",
            "36/36 [==============================] - 1s 19ms/step - loss: 0.0020 - mean_absolute_error: 0.0337 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "34/36 [===========================>..] - ETA: 0s - loss: 0.0019 - mean_absolute_error: 0.0336\n",
            "Epoch 19: loss did not improve from 0.00196\n",
            "36/36 [==============================] - 1s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0341 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "34/36 [===========================>..] - ETA: 0s - loss: 0.0016 - mean_absolute_error: 0.0306\n",
            "Epoch 20: loss improved from 0.00196 to 0.00165, saving model to weights.h5\n",
            "36/36 [==============================] - 1s 20ms/step - loss: 0.0016 - mean_absolute_error: 0.0310 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "34/36 [===========================>..] - ETA: 0s - loss: 0.0018 - mean_absolute_error: 0.0327\n",
            "Epoch 21: loss did not improve from 0.00165\n",
            "36/36 [==============================] - 1s 18ms/step - loss: 0.0018 - mean_absolute_error: 0.0325 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "34/36 [===========================>..] - ETA: 0s - loss: 0.0019 - mean_absolute_error: 0.0323\n",
            "Epoch 22: loss did not improve from 0.00165\n",
            "36/36 [==============================] - 1s 18ms/step - loss: 0.0018 - mean_absolute_error: 0.0317 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "34/36 [===========================>..] - ETA: 0s - loss: 0.0018 - mean_absolute_error: 0.0321\n",
            "Epoch 23: loss did not improve from 0.00165\n",
            "36/36 [==============================] - 1s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0316 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "34/36 [===========================>..] - ETA: 0s - loss: 0.0017 - mean_absolute_error: 0.0306\n",
            "Epoch 24: loss improved from 0.00165 to 0.00163, saving model to weights.h5\n",
            "36/36 [==============================] - 1s 19ms/step - loss: 0.0016 - mean_absolute_error: 0.0305 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "34/36 [===========================>..] - ETA: 0s - loss: 0.0018 - mean_absolute_error: 0.0318\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "\n",
            "Epoch 25: loss did not improve from 0.00163\n",
            "36/36 [==============================] - 1s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0315 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "34/36 [===========================>..] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0251\n",
            "Epoch 26: loss improved from 0.00163 to 0.00115, saving model to weights.h5\n",
            "36/36 [==============================] - 1s 19ms/step - loss: 0.0011 - mean_absolute_error: 0.0249 - lr: 2.0000e-04\n",
            "Epoch 27/100\n",
            "34/36 [===========================>..] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0243\n",
            "Epoch 27: loss improved from 0.00115 to 0.00110, saving model to weights.h5\n",
            "36/36 [==============================] - 1s 19ms/step - loss: 0.0011 - mean_absolute_error: 0.0245 - lr: 2.0000e-04\n",
            "Epoch 28/100\n",
            "34/36 [===========================>..] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0241\n",
            "Epoch 28: loss improved from 0.00110 to 0.00104, saving model to weights.h5\n",
            "36/36 [==============================] - 1s 19ms/step - loss: 0.0010 - mean_absolute_error: 0.0241 - lr: 2.0000e-04\n",
            "Epoch 29/100\n",
            "34/36 [===========================>..] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0252\n",
            "Epoch 29: loss did not improve from 0.00104\n",
            "36/36 [==============================] - 1s 19ms/step - loss: 0.0012 - mean_absolute_error: 0.0251 - lr: 2.0000e-04\n",
            "Epoch 30/100\n",
            "34/36 [===========================>..] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0237\n",
            "Epoch 30: loss improved from 0.00104 to 0.00103, saving model to weights.h5\n",
            "36/36 [==============================] - 1s 19ms/step - loss: 0.0010 - mean_absolute_error: 0.0236 - lr: 2.0000e-04\n",
            "Epoch 31/100\n",
            "34/36 [===========================>..] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0240\n",
            "Epoch 31: loss did not improve from 0.00103\n",
            "36/36 [==============================] - 1s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0241 - lr: 2.0000e-04\n",
            "Epoch 32/100\n",
            "34/36 [===========================>..] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0238\n",
            "Epoch 32: loss did not improve from 0.00103\n",
            "36/36 [==============================] - 1s 19ms/step - loss: 0.0010 - mean_absolute_error: 0.0236 - lr: 2.0000e-04\n",
            "Epoch 33/100\n",
            "34/36 [===========================>..] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0235\n",
            "Epoch 33: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "\n",
            "Epoch 33: loss improved from 0.00103 to 0.00101, saving model to weights.h5\n",
            "36/36 [==============================] - 1s 20ms/step - loss: 0.0010 - mean_absolute_error: 0.0233 - lr: 2.0000e-04\n",
            "Epoch 34/100\n",
            "34/36 [===========================>..] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0239\n",
            "Epoch 34: loss did not improve from 0.00101\n",
            "36/36 [==============================] - 1s 18ms/step - loss: 0.0010 - mean_absolute_error: 0.0238 - lr: 4.0000e-05\n",
            "Epoch 35/100\n",
            "34/36 [===========================>..] - ETA: 0s - loss: 9.7080e-04 - mean_absolute_error: 0.0231\n",
            "Epoch 35: loss improved from 0.00101 to 0.00098, saving model to weights.h5\n",
            "36/36 [==============================] - 1s 19ms/step - loss: 9.7923e-04 - mean_absolute_error: 0.0232 - lr: 4.0000e-05\n",
            "Epoch 36/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0233\n",
            "Epoch 36: loss did not improve from 0.00098\n",
            "36/36 [==============================] - 1s 19ms/step - loss: 0.0010 - mean_absolute_error: 0.0233 - lr: 4.0000e-05\n",
            "Epoch 37/100\n",
            "34/36 [===========================>..] - ETA: 0s - loss: 8.8531e-04 - mean_absolute_error: 0.0221\n",
            "Epoch 37: loss improved from 0.00098 to 0.00090, saving model to weights.h5\n",
            "36/36 [==============================] - 1s 19ms/step - loss: 8.9613e-04 - mean_absolute_error: 0.0222 - lr: 4.0000e-05\n",
            "Epoch 38/100\n",
            "34/36 [===========================>..] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0239\n",
            "Epoch 38: loss did not improve from 0.00090\n",
            "36/36 [==============================] - 1s 18ms/step - loss: 0.0010 - mean_absolute_error: 0.0237 - lr: 4.0000e-05\n",
            "Epoch 39/100\n",
            "34/36 [===========================>..] - ETA: 0s - loss: 9.6685e-04 - mean_absolute_error: 0.0224\n",
            "Epoch 39: loss did not improve from 0.00090\n",
            "36/36 [==============================] - 1s 18ms/step - loss: 9.7349e-04 - mean_absolute_error: 0.0226 - lr: 4.0000e-05\n",
            "Epoch 40/100\n",
            "34/36 [===========================>..] - ETA: 0s - loss: 9.4780e-04 - mean_absolute_error: 0.0225\n",
            "Epoch 40: loss did not improve from 0.00090\n",
            "36/36 [==============================] - 1s 18ms/step - loss: 9.4111e-04 - mean_absolute_error: 0.0224 - lr: 4.0000e-05\n",
            "Epoch 41/100\n",
            "34/36 [===========================>..] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0236\n",
            "Epoch 41: loss did not improve from 0.00090\n",
            "36/36 [==============================] - 1s 18ms/step - loss: 9.8287e-04 - mean_absolute_error: 0.0233 - lr: 4.0000e-05\n",
            "Epoch 42/100\n",
            "34/36 [===========================>..] - ETA: 0s - loss: 9.7274e-04 - mean_absolute_error: 0.0229\n",
            "Epoch 42: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "\n",
            "Epoch 42: loss did not improve from 0.00090\n",
            "36/36 [==============================] - 1s 18ms/step - loss: 9.5587e-04 - mean_absolute_error: 0.0227 - lr: 4.0000e-05\n",
            "Epoch 43/100\n",
            "34/36 [===========================>..] - ETA: 0s - loss: 9.7775e-04 - mean_absolute_error: 0.0224\n",
            "Epoch 43: loss did not improve from 0.00090\n",
            "36/36 [==============================] - 1s 19ms/step - loss: 9.7073e-04 - mean_absolute_error: 0.0222 - lr: 8.0000e-06\n",
            "Epoch 44/100\n",
            "34/36 [===========================>..] - ETA: 0s - loss: 9.1922e-04 - mean_absolute_error: 0.0226\n",
            "Epoch 44: loss did not improve from 0.00090\n",
            "36/36 [==============================] - 1s 18ms/step - loss: 9.2946e-04 - mean_absolute_error: 0.0225 - lr: 8.0000e-06\n",
            "Epoch 45/100\n",
            "34/36 [===========================>..] - ETA: 0s - loss: 9.1643e-04 - mean_absolute_error: 0.0220\n",
            "Epoch 45: loss did not improve from 0.00090\n",
            "36/36 [==============================] - 1s 18ms/step - loss: 9.2833e-04 - mean_absolute_error: 0.0220 - lr: 8.0000e-06\n",
            "Epoch 46/100\n",
            "34/36 [===========================>..] - ETA: 0s - loss: 9.7193e-04 - mean_absolute_error: 0.0230\n",
            "Epoch 46: loss did not improve from 0.00090\n",
            "36/36 [==============================] - 1s 19ms/step - loss: 9.6467e-04 - mean_absolute_error: 0.0230 - lr: 8.0000e-06\n",
            "Epoch 47/100\n",
            "34/36 [===========================>..] - ETA: 0s - loss: 9.0100e-04 - mean_absolute_error: 0.0221\n",
            "Epoch 47: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00090\n",
            "36/36 [==============================] - 1s 18ms/step - loss: 9.2222e-04 - mean_absolute_error: 0.0224 - lr: 8.0000e-06\n",
            "Epoch 47: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3e5c7370d0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Refazendo os mesmos passos para o aquivo de teste\n",
        "base_test = pd.read_csv('petr4_teste.csv')\n",
        "base_test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "2QOW9F4VXAJV",
        "outputId": "c6a1883f-1885-4525-e06e-1a4c2be9b27d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Date       Open       High        Low      Close  Adj Close    Volume\n",
              "0  2018-01-02  16.190001  16.549999  16.190001  16.549999  16.516966  33461800\n",
              "1  2018-01-03  16.490000  16.719999  16.370001  16.700001  16.666668  55940900\n",
              "2  2018-01-04  16.780001  16.959999  16.620001  16.730000  16.696608  37064900\n",
              "3  2018-01-05  16.700001  16.860001  16.570000  16.830000  16.796408  26958200\n",
              "4  2018-01-08  16.740000  17.030001  16.709999  17.030001  16.996010  28400000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d032c6d1-2e8f-497d-b62b-c67b91284e2b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-01-02</td>\n",
              "      <td>16.190001</td>\n",
              "      <td>16.549999</td>\n",
              "      <td>16.190001</td>\n",
              "      <td>16.549999</td>\n",
              "      <td>16.516966</td>\n",
              "      <td>33461800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-01-03</td>\n",
              "      <td>16.490000</td>\n",
              "      <td>16.719999</td>\n",
              "      <td>16.370001</td>\n",
              "      <td>16.700001</td>\n",
              "      <td>16.666668</td>\n",
              "      <td>55940900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-01-04</td>\n",
              "      <td>16.780001</td>\n",
              "      <td>16.959999</td>\n",
              "      <td>16.620001</td>\n",
              "      <td>16.730000</td>\n",
              "      <td>16.696608</td>\n",
              "      <td>37064900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-01-05</td>\n",
              "      <td>16.700001</td>\n",
              "      <td>16.860001</td>\n",
              "      <td>16.570000</td>\n",
              "      <td>16.830000</td>\n",
              "      <td>16.796408</td>\n",
              "      <td>26958200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-01-08</td>\n",
              "      <td>16.740000</td>\n",
              "      <td>17.030001</td>\n",
              "      <td>16.709999</td>\n",
              "      <td>17.030001</td>\n",
              "      <td>16.996010</td>\n",
              "      <td>28400000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d032c6d1-2e8f-497d-b62b-c67b91284e2b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d032c6d1-2e8f-497d-b62b-c67b91284e2b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d032c6d1-2e8f-497d-b62b-c67b91284e2b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "real_price_teste = base_test.iloc[:,1:2].values"
      ],
      "metadata": {
        "id": "8YJ-MgBnXjid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frames = [base,base_test]\n",
        "base_complet = pd.concat(frames)"
      ],
      "metadata": {
        "id": "a67t1vWuXunU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_complet = base_complet.drop('Date',axis=1)"
      ],
      "metadata": {
        "id": "mUjCn4XTPTfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = base_complet[len(base_complet) - len(base_test) - 90:].values"
      ],
      "metadata": {
        "id": "lb3q98WdRIM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = normalized.transform(outputs)"
      ],
      "metadata": {
        "id": "5-4rzqFdRYyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = []\n",
        "for i in range(90,112):\n",
        "  X_test.append(outputs[i-90:i,0:6])\n",
        "X_test = np.array(X_test)"
      ],
      "metadata": {
        "id": "JCO0W1a-R19E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictors_tst = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxnbuLmBSya7",
        "outputId": "1d8a5b89-3a35-41f1-d04a-d57951ea819b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictors_tst = normalized_predictors.inverse_transform(predictors_tst)"
      ],
      "metadata": {
        "id": "it8e8GxSTsdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(real_price_teste,color='red',label='Real Price')\n",
        "plt.plot(predictors_tst,color='blue',label='Predictions')\n",
        "plt.title('Stock Price Forecast')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Yahoo Values')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "sK1WUgVqUXKV",
        "outputId": "5564f8c2-5570-4322-f07f-bc8ca42bee9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}